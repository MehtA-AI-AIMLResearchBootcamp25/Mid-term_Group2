{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMhNlDr2NdceUqOqsZ2WAP2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neural-anarchist/AI_Text_Annotation/blob/main/rhet_recognizationai_gemini.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzWw_Itjlwxw",
        "outputId": "53a29336-8c2a-437d-d239-b694e0cac678"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Collecting backoff\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.176.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.14.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.73.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.7.14)\n",
            "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: backoff\n",
            "Successfully installed backoff-2.2.1\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Medieval Spanish/Catalan Text Annotation Model\n",
        "==============================================\n",
        "\n",
        "A production-ready system for annotating medieval Spanish and Catalan texts\n",
        "with literary, rhetorical, and linguistic taxonomies.\n",
        "\n",
        "Author: Gary Shen\n",
        "Version: 1.0.0\n",
        "License: MIT\n",
        "\n",
        "Usage:\n",
        "\n",
        "    annotator = MedievalTextAnnotator(api_key=\"your_gemini_api_key\")\n",
        "    result = annotator.annotate_text(\"Your medieval text here...\")\n",
        "\n",
        "    # Access results\n",
        "    print(f\"Found {result.total_annotations} annotations\")\n",
        "    xml_output = result.xml_output\n",
        "    csv_data = result.csv_output\n",
        "    json_data = result.json_output\n",
        "\"\"\"\n",
        "\n",
        "!pip install pandas google-generativeai backoff\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import json\n",
        "import logging\n",
        "import traceback\n",
        "from typing import List, Dict, Optional, Any, Tuple\n",
        "from dataclasses import dataclass, field\n",
        "from collections import Counter\n",
        "import xml.etree.ElementTree as ET\n",
        "from xml.dom import minidom\n",
        "\n",
        "\n",
        "# Required dependencies\n",
        "try:\n",
        "    import pandas as pd\n",
        "    import google.generativeai as genai\n",
        "    import backoff\n",
        "except ImportError as e:\n",
        "    raise ImportError(f\"Missing required dependency: {e}. Please install with: pip install pandas google-generativeai backoff\")\n",
        "\n",
        "# =============================================================================\n",
        "# CONFIGURATION AND CONSTANTS\n",
        "# =============================================================================\n",
        "\n",
        "# Medieval Spanish/Catalan Literary Taxonomy\n",
        "TAXONOMY = {\n",
        "    \"Genre\": [\"sermon\", \"vision\", \"consolatory_treatise\", \"vita\", \"confession\",\n",
        "              \"prayer_devotional\", \"disputation\", \"performance\", \"music\", \"parable\",\n",
        "              \"sacraments\", \"didactics\", \"scripture\", \"autobiography\", \"dialogue\",\n",
        "              \"exemplum\", \"epistle\", \"theater_performance\", \"poetry\", \"music_laic\",\n",
        "              \"testament_will\", \"speculum\", \"relacion\", \"genealogy\", \"testimony\",\n",
        "              \"disputation_laic\", \"pastoral\"],\n",
        "\n",
        "    \"Rhetoric\": [\"captatio\", \"colloquialism\", \"pathos\", \"logos\", \"ethos\", \"allegory\",\n",
        "                 \"ekphrasis\", \"metaphor\", \"sign_symbol\", \"exegesis\", \"parallelism\",\n",
        "                 \"didactics_rhet\", \"invective\", \"amplification\", \"anaphora\", \"antithesis\",\n",
        "                 \"apostrophe\", \"exclamation\", \"polyptoton\", \"hypophora\", \"orality_literacy\"],\n",
        "\n",
        "    \"Lexis\": [\"place\", \"person\", \"name\", \"gender\", \"building\", \"family\", \"authority\",\n",
        "              \"body\", \"soul\", \"material\", \"nature\", \"animal\", \"time\", \"age\", \"food\",\n",
        "              \"festivity\", \"latin\", \"sins\", \"virtues\", \"vice\"],\n",
        "\n",
        "    \"Verb_Functions\": [\"affirm\", \"negate\", \"question\", \"exhort\", \"narrate\", \"describe\",\n",
        "                       \"command\", \"promise\", \"lament\", \"praise\", \"blame\", \"warn\",\n",
        "                       \"supplicate\", \"advise\", \"instruct\", \"prophesy\", \"invoke\", \"confess\"],\n",
        "\n",
        "    \"Notes\": [\"hkbtext\", \"hkbobs\", \"intertext\", \"classical_sources\", \"biblical_sources\",\n",
        "              \"contemporary_sources\", \"metatextual\"]\n",
        "}\n",
        "\n",
        "# Create validation sets\n",
        "ALL_VALID_SUBTYPES = set()\n",
        "for subtypes in TAXONOMY.values():\n",
        "    ALL_VALID_SUBTYPES.update(subtypes)\n",
        "\n",
        "# Common subtype corrections for LLM responses\n",
        "SUBTYPE_CORRECTIONS = {\n",
        "    \"capitatio\": \"captatio\",\n",
        "    \"capitio\": \"captatio\",\n",
        "    \"person_name\": \"person\",\n",
        "    \"person_man\": \"person\",\n",
        "    \"person_woman\": \"person\",\n",
        "    \"description\": \"describe\",\n",
        "    \"affirmation\": \"affirm\",\n",
        "    \"negation\": \"negate\",\n",
        "    \"questioning\": \"question\",\n",
        "    \"exhortation\": \"exhort\",\n",
        "    \"narration\": \"narrate\",\n",
        "    \"commanding\": \"command\",\n",
        "    \"promising\": \"promise\",\n",
        "    \"lamenting\": \"lament\",\n",
        "    \"praising\": \"praise\",\n",
        "    \"blaming\": \"blame\",\n",
        "    \"warning\": \"warn\",\n",
        "    \"supplication\": \"supplicate\",\n",
        "    \"advising\": \"advise\",\n",
        "    \"instruction\": \"instruct\",\n",
        "    \"instructing\": \"instruct\",\n",
        "    \"prophecy\": \"prophesy\",\n",
        "    \"prophesying\": \"prophesy\",\n",
        "    \"invocation\": \"invoke\",\n",
        "    \"invoking\": \"invoke\",\n",
        "    \"confession\": \"confess\",\n",
        "    \"confessing\": \"confess\"\n",
        "}\n",
        "\n",
        "# =============================================================================\n",
        "# DATA STRUCTURES\n",
        "# =============================================================================\n",
        "\n",
        "@dataclass\n",
        "class SpanAnnotation:\n",
        "    \"\"\"Represents a single text annotation with span information.\"\"\"\n",
        "    text: str\n",
        "    start: int\n",
        "    end: int\n",
        "    type: str\n",
        "    subtype: str\n",
        "    confidence: float = 1.0\n",
        "\n",
        "    def to_dict(self) -> Dict[str, Any]:\n",
        "        \"\"\"Convert to dictionary format for JSON serialization.\"\"\"\n",
        "        return {\n",
        "            \"span\": {\n",
        "                \"text\": self.text,\n",
        "                \"start\": self.start,\n",
        "                \"end\": self.end\n",
        "            },\n",
        "            \"type\": self.type,\n",
        "            \"subtype\": self.subtype,\n",
        "            \"confidence\": self.confidence\n",
        "        }\n",
        "\n",
        "    def __str__(self) -> str:\n",
        "        return f\"'{self.text}' ({self.type}:{self.subtype}) [{self.start}:{self.end}]\"\n",
        "\n",
        "@dataclass\n",
        "class ChunkAnnotation:\n",
        "    \"\"\"Container for all annotations in a text chunk.\"\"\"\n",
        "    chunk_index: int\n",
        "    original_text: str\n",
        "    annotations: List[SpanAnnotation]\n",
        "    processing_time: float\n",
        "    chunk_size: int = field(init=False)\n",
        "\n",
        "    def __post_init__(self):\n",
        "        self.chunk_size = len(self.original_text)\n",
        "\n",
        "    def to_ml_format(self) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Convert to ML training format.\"\"\"\n",
        "        return [ann.to_dict() for ann in self.annotations]\n",
        "\n",
        "    @property\n",
        "    def annotation_count(self) -> int:\n",
        "        \"\"\"Get the number of annotations in this chunk.\"\"\"\n",
        "        return len(self.annotations)\n",
        "\n",
        "@dataclass\n",
        "class AnnotationResult:\n",
        "    \"\"\"Complete annotation result with all output formats.\"\"\"\n",
        "    xml_output: str\n",
        "    csv_output: pd.DataFrame\n",
        "    json_output: Dict[str, Any]\n",
        "    total_annotations: int\n",
        "    processing_time: float\n",
        "    chunk_count: int\n",
        "    statistics: Dict[str, Any]\n",
        "    chunks: List[ChunkAnnotation] = field(default_factory=list)\n",
        "\n",
        "    def save_outputs(self, output_dir: str, base_filename: str = \"annotations\") -> Dict[str, str]:\n",
        "        \"\"\"Save all outputs to files and return file paths.\"\"\"\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        file_paths = {}\n",
        "\n",
        "        # Save XML\n",
        "        xml_path = os.path.join(output_dir, f\"{base_filename}.xml\")\n",
        "        with open(xml_path, 'w', encoding='utf-8') as f:\n",
        "            f.write(self.xml_output)\n",
        "        file_paths['xml'] = xml_path\n",
        "\n",
        "        # Save CSV\n",
        "        csv_path = os.path.join(output_dir, f\"{base_filename}.csv\")\n",
        "        self.csv_output.to_csv(csv_path, index=False, encoding='utf-8')\n",
        "        file_paths['csv'] = csv_path\n",
        "\n",
        "        # Save JSON\n",
        "        json_path = os.path.join(output_dir, f\"{base_filename}_ml_data.json\")\n",
        "        with open(json_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(self.json_output, f, ensure_ascii=False, indent=2)\n",
        "        file_paths['json'] = json_path\n",
        "\n",
        "        return file_paths\n",
        "\n",
        "# =============================================================================\n",
        "# TEXT PROCESSING UTILITIES\n",
        "# =============================================================================\n",
        "\n",
        "class TextProcessor:\n",
        "    \"\"\"Handles text cleaning and chunking operations.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def clean_extracted_text(text: str) -> str:\n",
        "        \"\"\"Comprehensive text cleaning for Medieval Spanish/Catalan texts.\"\"\"\n",
        "        if not text:\n",
        "            return \"\"\n",
        "\n",
        "        original_length = len(text)\n",
        "\n",
        "        # OCR artifacts and modern additions\n",
        "        ocr_patterns = [\n",
        "            r'\\bPage\\s+\\d+\\b',\n",
        "            r'\\bFolio\\s+\\d+[rv]?\\b',\n",
        "            r'\\[p\\.\\s*\\d+\\]',\n",
        "            r'\\b\\d{1,3}\\s+of\\s+\\d{1,3}\\b',\n",
        "            r'^\\s*\\d+\\s*$',\n",
        "            r'^\\s*[IVXLCDM]+\\s*$',\n",
        "            r'\\d{1,2}/\\d{1,2}/\\d{2,4}\\s+\\d{1,2}:\\d{2}(?:\\:\\d{2})?\\s*[AP]M',\n",
        "            r'\\d{4}-\\d{2}-\\d{2}\\s+\\d{2}:\\d{2}:\\d{2}',\n",
        "            r'https?://\\S+',\n",
        "            r'www\\.\\S+',\n",
        "            r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b',\n",
        "            r'\\bOCRed\\b',\n",
        "            r'\\bOCR\\b',\n",
        "            r'Scanned\\s+by.*?Internet\\s+Archive',\n",
        "            r'Digitized\\s+by.*?Google',\n",
        "            r'Archive\\.org',\n",
        "            r'Publicaciones.*?Montoto',\n",
        "            r'Reflexiones.*?antiguo',\n",
        "            r'Transcription\\s+of\\s+.*?TERESA\\s+DE\\s+CARTAGENA',\n",
        "            r'TERESA\\s+DE\\s+CARTAGENA',\n",
        "            r'^\\s*[-*•]\\s*$',\n",
        "            r'^\\s*[_=\\-]{3,}\\s*$',\n",
        "            r'\\[.*?\\](?:\\s*\\[.*?\\])*',\n",
        "            r'(?:^|\\n)\\s*(?:CHAPTER|CAPÍTULO|CAP\\.)\\s+[IVXLCDM\\d]+\\s*(?:\\n|$)',\n",
        "            r'(?:^|\\n)\\s*\\d+\\s*(?:\\n|$)',\n",
        "        ]\n",
        "\n",
        "        # Apply cleaning patterns\n",
        "        for pattern in ocr_patterns:\n",
        "            text = re.sub(pattern, '', text, flags=re.IGNORECASE | re.MULTILINE)\n",
        "\n",
        "        # Normalize whitespace and punctuation\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "        text = re.sub(r'\\n\\s*\\n+', '\\n\\n', text)\n",
        "        text = re.sub(r'([.!?])([A-ZÁÉÍÓÚÑÇ])', r'\\1 \\2', text)\n",
        "        text = re.sub(r'([,;:])([A-ZÁÉÍÓÚÑÇ])', r'\\1 \\2', text)\n",
        "\n",
        "        # Fix Medieval Spanish/Catalan character issues\n",
        "        char_fixes = [\n",
        "            (r'([aeiouáéíóú])n([aeiouáéíóú])', r'\\1ñ\\2'),\n",
        "            (r'([aeiouáéíóú])c([aeiouáéíóú])', r'\\1ç\\2'),\n",
        "            (r'(\\w)j(\\w)', r'\\1i\\2'),\n",
        "            (r'(\\w)v(\\w)', r'\\1u\\2'),\n",
        "            (r'\\bu(\\w)', r'v\\1'),\n",
        "        ]\n",
        "\n",
        "        for pattern, replacement in char_fixes:\n",
        "            text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)\n",
        "\n",
        "        # Clean up excessive punctuation\n",
        "        text = re.sub(r'[.]{3,}', '...', text)\n",
        "        text = re.sub(r'[,]{2,}', ',', text)\n",
        "        text = re.sub(r'[;]{2,}', ';', text)\n",
        "        text = re.sub(r'[!]{2,}', '!', text)\n",
        "        text = re.sub(r'[?]{2,}', '?', text)\n",
        "\n",
        "        # Final cleanup\n",
        "        text = text.strip()\n",
        "        text = re.sub(r'\\n\\s*\\n\\s*\\n+', '\\n\\n', text)\n",
        "\n",
        "        cleaned_length = len(text)\n",
        "        removed_percentage = ((original_length - cleaned_length) / original_length) * 100 if original_length > 0 else 0\n",
        "\n",
        "        logging.info(f\"Text cleaned: {original_length} → {cleaned_length} chars ({removed_percentage:.1f}% removed)\")\n",
        "\n",
        "        return text\n",
        "\n",
        "    @staticmethod\n",
        "    def chunk_text_intelligently(text: str, max_chunk_size: int = 1500) -> List[str]:\n",
        "        \"\"\"Smart text chunking that respects sentence and paragraph boundaries.\"\"\"\n",
        "        if not text or len(text) <= max_chunk_size:\n",
        "            return [text] if text else []\n",
        "\n",
        "        chunks = []\n",
        "        current_chunk = \"\"\n",
        "\n",
        "        # Split by paragraphs first\n",
        "        paragraphs = text.split('\\n\\n')\n",
        "\n",
        "        for paragraph in paragraphs:\n",
        "            paragraph = paragraph.strip()\n",
        "            if not paragraph:\n",
        "                continue\n",
        "\n",
        "            # If paragraph is too long, split by sentences\n",
        "            if len(paragraph) > max_chunk_size:\n",
        "                sentences = re.split(r'(?<=[.!?])\\s+', paragraph)\n",
        "\n",
        "                for sentence in sentences:\n",
        "                    sentence = sentence.strip()\n",
        "                    if not sentence:\n",
        "                        continue\n",
        "\n",
        "                    # Check if adding sentence would exceed limit\n",
        "                    if len(current_chunk) + len(sentence) + 2 > max_chunk_size:\n",
        "                        if current_chunk.strip():\n",
        "                            chunks.append(current_chunk.strip())\n",
        "                        current_chunk = sentence\n",
        "                    else:\n",
        "                        current_chunk += (\" \" + sentence) if current_chunk else sentence\n",
        "            else:\n",
        "                # Check if adding paragraph would exceed limit\n",
        "                if len(current_chunk) + len(paragraph) + 2 > max_chunk_size:\n",
        "                    if current_chunk.strip():\n",
        "                        chunks.append(current_chunk.strip())\n",
        "                    current_chunk = paragraph\n",
        "                else:\n",
        "                    current_chunk += (\"\\n\\n\" + paragraph) if current_chunk else paragraph\n",
        "\n",
        "        # Add final chunk\n",
        "        if current_chunk.strip():\n",
        "            chunks.append(current_chunk.strip())\n",
        "\n",
        "        # Filter out very short chunks\n",
        "        chunks = [chunk for chunk in chunks if len(chunk) >= 50]\n",
        "\n",
        "        logging.info(f\"Created {len(chunks)} intelligent chunks\")\n",
        "        return chunks\n",
        "\n",
        "# =============================================================================\n",
        "# LLM INTEGRATION\n",
        "# =============================================================================\n",
        "\n",
        "class LLMAnnotator:\n",
        "    \"\"\"Handles interaction with Gemini API for annotation.\"\"\"\n",
        "\n",
        "    def __init__(self, api_key: str, model_name: str = 'gemini-1.5-flash'):\n",
        "        \"\"\"Initialize LLM annotator with API key.\"\"\"\n",
        "        self.api_key = api_key\n",
        "        self.model_name = model_name\n",
        "        self._configure_api()\n",
        "\n",
        "    def _configure_api(self):\n",
        "        \"\"\"Configure Gemini API.\"\"\"\n",
        "        try:\n",
        "            genai.configure(api_key=self.api_key)\n",
        "            self.model = genai.GenerativeModel(self.model_name)\n",
        "            logging.info(f\"Gemini API configured with model: {self.model_name}\")\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"Failed to configure Gemini API: {e}\")\n",
        "\n",
        "    def _create_annotation_prompt(self, text_chunk: str) -> str:\n",
        "        \"\"\"Create comprehensive annotation prompt.\"\"\"\n",
        "        taxonomy_desc = \"\"\n",
        "        for category, subtypes in TAXONOMY.items():\n",
        "            taxonomy_desc += f\"\\n{category}:\\n\"\n",
        "            for subtype in subtypes[:8]:  # Limit to avoid token overflow\n",
        "                taxonomy_desc += f\"  - {subtype}\\n\"\n",
        "            if len(subtypes) > 8:\n",
        "                taxonomy_desc += f\"  ... and {len(subtypes) - 8} more\\n\"\n",
        "\n",
        "        prompt = f\"\"\"You are an expert in Medieval Spanish and Catalan literature. Analyze the following text and identify meaningful spans that fit these categories:\n",
        "\n",
        "{taxonomy_desc}\n",
        "\n",
        "ANNOTATION RULES:\n",
        "1. Only use the exact subtypes listed above\n",
        "2. Identify spans of 2-50 words that clearly represent each category\n",
        "3. Focus on significant literary, rhetorical, and semantic elements\n",
        "4. Spans should not overlap\n",
        "5. Return ONLY valid JSON array format\n",
        "6. Be precise with character positions\n",
        "\n",
        "EXAMPLES:\n",
        "- \"Teresa de Cartagena\" → {{\"span\": {{\"text\": \"Teresa de Cartagena\", \"start\": 0, \"end\": 18}}, \"type\": \"Lexis\", \"subtype\": \"person\"}}\n",
        "- \"en el año de 1425\" → {{\"span\": {{\"text\": \"año de 1425\", \"start\": 6, \"end\": 17}}, \"type\": \"Lexis\", \"subtype\": \"time\"}}\n",
        "- \"Dios todopoderoso\" → {{\"span\": {{\"text\": \"Dios todopoderoso\", \"start\": 0, \"end\": 17}}, \"type\": \"Lexis\", \"subtype\": \"authority\"}}\n",
        "\n",
        "TEXT TO ANALYZE ({len(text_chunk)} characters):\n",
        "{text_chunk}\n",
        "\n",
        "Return JSON array with this exact format:\n",
        "[{{\"span\": {{\"text\": \"exact_text_from_above\", \"start\": start_index, \"end\": end_index}}, \"type\": \"Category\", \"subtype\": \"exact_subtype\"}}]\n",
        "\n",
        "JSON:\"\"\"\n",
        "\n",
        "        return prompt\n",
        "\n",
        "    @backoff.on_exception(backoff.expo, Exception, max_tries=3, max_time=60)\n",
        "    def _call_gemini_api(self, prompt: str) -> str:\n",
        "        \"\"\"Call Gemini API with retry logic.\"\"\"\n",
        "        try:\n",
        "            response = self.model.generate_content(prompt)\n",
        "            return response.text if response.text else \"\"\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Gemini API error: {e}\")\n",
        "            raise\n",
        "\n",
        "    def _correct_subtype(self, subtype: str) -> str:\n",
        "        \"\"\"Correct common subtype errors.\"\"\"\n",
        "        subtype_lower = subtype.lower()\n",
        "        return SUBTYPE_CORRECTIONS.get(subtype_lower, subtype)\n",
        "\n",
        "    def _validate_annotation(self, annotation: Dict, original_text: str) -> Optional[SpanAnnotation]:\n",
        "        \"\"\"Validate and clean a single annotation.\"\"\"\n",
        "        try:\n",
        "            # Extract span information\n",
        "            span = annotation.get('span', {})\n",
        "            if not isinstance(span, dict):\n",
        "                return None\n",
        "\n",
        "            text = span.get('text', '')\n",
        "            start = span.get('start')\n",
        "            end = span.get('end')\n",
        "            ann_type = annotation.get('type', '')\n",
        "            subtype = annotation.get('subtype', '')\n",
        "\n",
        "            # Validate required fields\n",
        "            if not all([text, isinstance(start, int), isinstance(end, int), ann_type, subtype]):\n",
        "                return None\n",
        "\n",
        "            # Validate indices\n",
        "            if start < 0 or end > len(original_text) or start >= end:\n",
        "                return None\n",
        "\n",
        "            # Validate type exists in taxonomy\n",
        "            if ann_type not in TAXONOMY:\n",
        "                return None\n",
        "\n",
        "            # Correct and validate subtype\n",
        "            subtype = self._correct_subtype(subtype)\n",
        "            if subtype not in TAXONOMY[ann_type]:\n",
        "                return None\n",
        "\n",
        "            # Validate text matches\n",
        "            expected_text = original_text[start:end]\n",
        "            if text.strip() != expected_text.strip():\n",
        "                # Try to find the text in the original\n",
        "                text_index = original_text.find(text.strip())\n",
        "                if text_index != -1:\n",
        "                    start = text_index\n",
        "                    end = text_index + len(text.strip())\n",
        "                else:\n",
        "                    return None\n",
        "\n",
        "            return SpanAnnotation(\n",
        "                text=text.strip(),\n",
        "                start=start,\n",
        "                end=end,\n",
        "                type=ann_type,\n",
        "                subtype=subtype\n",
        "            )\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.debug(f\"Error validating annotation: {e}\")\n",
        "            return None\n",
        "\n",
        "    def _parse_gemini_response(self, response_text: str, original_text: str) -> List[SpanAnnotation]:\n",
        "        \"\"\"Parse Gemini response and extract valid annotations.\"\"\"\n",
        "        if not response_text:\n",
        "            return []\n",
        "\n",
        "        # Extract JSON from response\n",
        "        json_patterns = [\n",
        "            r'\\[[\\s\\S]*?\\]',\n",
        "            r'```json\\s*(\\[[\\s\\S]*?\\])\\s*```',\n",
        "            r'json\\s*(\\[[\\s\\S]*?\\])',\n",
        "        ]\n",
        "\n",
        "        json_text = None\n",
        "        for pattern in json_patterns:\n",
        "            match = re.search(pattern, response_text, re.DOTALL)\n",
        "            if match:\n",
        "                json_text = match.group(1) if match.groups() else match.group(0)\n",
        "                break\n",
        "\n",
        "        if not json_text:\n",
        "            logging.debug(\"No JSON found in LLM response\")\n",
        "            return []\n",
        "\n",
        "        try:\n",
        "            # Clean and parse JSON\n",
        "            json_text = json_text.strip()\n",
        "            if not json_text.startswith('['):\n",
        "                json_text = '[' + json_text\n",
        "            if not json_text.endswith(']'):\n",
        "                json_text = json_text + ']'\n",
        "\n",
        "            annotations_data = json.loads(json_text)\n",
        "            if not isinstance(annotations_data, list):\n",
        "                return []\n",
        "\n",
        "            # Validate each annotation\n",
        "            valid_annotations = []\n",
        "            for ann_data in annotations_data:\n",
        "                validated = self._validate_annotation(ann_data, original_text)\n",
        "                if validated:\n",
        "                    valid_annotations.append(validated)\n",
        "\n",
        "            return valid_annotations\n",
        "\n",
        "        except json.JSONDecodeError as e:\n",
        "            logging.debug(f\"JSON parsing error: {e}\")\n",
        "            return []\n",
        "        except Exception as e:\n",
        "            logging.debug(f\"Unexpected error parsing response: {e}\")\n",
        "            return []\n",
        "\n",
        "    def annotate_chunk(self, chunk: str, chunk_index: int) -> ChunkAnnotation:\n",
        "        \"\"\"Annotate a single text chunk.\"\"\"\n",
        "        start_time = time.time()\n",
        "\n",
        "        try:\n",
        "            # Create prompt\n",
        "            prompt = self._create_annotation_prompt(chunk)\n",
        "\n",
        "            # Call API\n",
        "            response = self._call_gemini_api(prompt)\n",
        "\n",
        "            # Parse response\n",
        "            annotations = self._parse_gemini_response(response, chunk)\n",
        "\n",
        "            processing_time = time.time() - start_time\n",
        "\n",
        "            logging.info(f\"Chunk {chunk_index}: {len(annotations)} annotations in {processing_time:.1f}s\")\n",
        "\n",
        "            return ChunkAnnotation(\n",
        "                chunk_index=chunk_index,\n",
        "                original_text=chunk,\n",
        "                annotations=annotations,\n",
        "                processing_time=processing_time\n",
        "            )\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error annotating chunk {chunk_index}: {e}\")\n",
        "            return ChunkAnnotation(\n",
        "                chunk_index=chunk_index,\n",
        "                original_text=chunk,\n",
        "                annotations=[],\n",
        "                processing_time=time.time() - start_time\n",
        "            )\n",
        "\n",
        "# =============================================================================\n",
        "# OUTPUT GENERATORS\n",
        "# =============================================================================\n",
        "\n",
        "class OutputGenerator:\n",
        "    \"\"\"Handles generation of XML, CSV, and JSON outputs.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_xml_output(chunk_annotations: List[ChunkAnnotation],\n",
        "                          source_info: str = \"user_input\") -> str:\n",
        "        \"\"\"Generate XML output with embedded annotations.\"\"\"\n",
        "        # Create root element\n",
        "        root = ET.Element('annotated_text')\n",
        "        root.set('created', time.strftime('%Y-%m-%d %H:%M:%S'))\n",
        "        root.set('total_chunks', str(len(chunk_annotations)))\n",
        "\n",
        "        # Add metadata\n",
        "        metadata = ET.SubElement(root, 'metadata')\n",
        "\n",
        "        # Source info\n",
        "        source_elem = ET.SubElement(metadata, 'source')\n",
        "        source_elem.text = source_info\n",
        "\n",
        "        # Add taxonomy\n",
        "        taxonomy_elem = ET.SubElement(metadata, 'taxonomy')\n",
        "        for category, subtypes in TAXONOMY.items():\n",
        "            cat_elem = ET.SubElement(taxonomy_elem, 'category')\n",
        "            cat_elem.set('name', category)\n",
        "            for subtype in subtypes:\n",
        "                sub_elem = ET.SubElement(cat_elem, 'subtype')\n",
        "                sub_elem.text = subtype\n",
        "\n",
        "        # Add annotated chunks\n",
        "        body = ET.SubElement(root, 'body')\n",
        "        total_annotations = 0\n",
        "\n",
        "        for chunk_annotation in chunk_annotations:\n",
        "            chunk_elem = ET.SubElement(body, 'chunk')\n",
        "            chunk_elem.set('index', str(chunk_annotation.chunk_index))\n",
        "            chunk_elem.set('length', str(chunk_annotation.chunk_size))\n",
        "            chunk_elem.set('annotations', str(chunk_annotation.annotation_count))\n",
        "            chunk_elem.set('processing_time', f\"{chunk_annotation.processing_time:.2f}\")\n",
        "\n",
        "            if chunk_annotation.annotations:\n",
        "                # Sort annotations by start position\n",
        "                sorted_annotations = sorted(chunk_annotation.annotations, key=lambda x: x.start)\n",
        "\n",
        "                # Build annotated text\n",
        "                text_elem = ET.SubElement(chunk_elem, 'text')\n",
        "                last_end = 0\n",
        "\n",
        "                for ann in sorted_annotations:\n",
        "                    # Add plain text before annotation\n",
        "                    if ann.start > last_end:\n",
        "                        plain_text = chunk_annotation.original_text[last_end:ann.start]\n",
        "                        if plain_text.strip():\n",
        "                            plain_elem = ET.SubElement(text_elem, 'plain')\n",
        "                            plain_elem.text = plain_text\n",
        "\n",
        "                    # Add annotated segment\n",
        "                    seg_elem = ET.SubElement(text_elem, 'seg')\n",
        "                    seg_elem.set('type', ann.type)\n",
        "                    seg_elem.set('subtype', ann.subtype)\n",
        "                    seg_elem.set('start', str(ann.start))\n",
        "                    seg_elem.set('end', str(ann.end))\n",
        "                    seg_elem.text = ann.text\n",
        "\n",
        "                    last_end = ann.end\n",
        "\n",
        "                # Add remaining plain text\n",
        "                if last_end < len(chunk_annotation.original_text):\n",
        "                    remaining_text = chunk_annotation.original_text[last_end:]\n",
        "                    if remaining_text.strip():\n",
        "                        plain_elem = ET.SubElement(text_elem, 'plain')\n",
        "                        plain_elem.text = remaining_text\n",
        "\n",
        "                total_annotations += len(chunk_annotation.annotations)\n",
        "            else:\n",
        "                # No annotations, just add original text\n",
        "                text_elem = ET.SubElement(chunk_elem, 'text')\n",
        "                plain_elem = ET.SubElement(text_elem, 'plain')\n",
        "                plain_elem.text = chunk_annotation.original_text\n",
        "\n",
        "        # Add summary statistics\n",
        "        summary = ET.SubElement(metadata, 'summary')\n",
        "        summary.set('total_annotations', str(total_annotations))\n",
        "\n",
        "        # Calculate statistics\n",
        "        type_counts = Counter()\n",
        "        subtype_counts = Counter()\n",
        "\n",
        "        for chunk in chunk_annotations:\n",
        "            for ann in chunk.annotations:\n",
        "                type_counts[ann.type] += 1\n",
        "                subtype_counts[f\"{ann.type}:{ann.subtype}\"] += 1\n",
        "\n",
        "        # Add type statistics\n",
        "        if type_counts:\n",
        "            types_elem = ET.SubElement(summary, 'types')\n",
        "            for type_name, count in type_counts.most_common():\n",
        "                type_stat = ET.SubElement(types_elem, 'type')\n",
        "                type_stat.set('name', type_name)\n",
        "                type_stat.set('count', str(count))\n",
        "\n",
        "        # Add subtype statistics\n",
        "        if subtype_counts:\n",
        "            subtypes_elem = ET.SubElement(summary, 'subtypes')\n",
        "            for subtype_name, count in subtype_counts.most_common():\n",
        "                subtype_stat = ET.SubElement(subtypes_elem, 'subtype')\n",
        "                subtype_stat.set('name', subtype_name)\n",
        "                subtype_stat.set('count', str(count))\n",
        "\n",
        "        # Convert to pretty XML\n",
        "        rough_string = ET.tostring(root, encoding='unicode')\n",
        "        reparsed = minidom.parseString(rough_string)\n",
        "        return reparsed.toprettyxml(indent='  ')\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_csv_output(chunk_annotations: List[ChunkAnnotation],\n",
        "                          source_info: str = \"user_input\") -> pd.DataFrame:\n",
        "        \"\"\"Generate CSV output with annotation data.\"\"\"\n",
        "        rows = []\n",
        "\n",
        "        for chunk_annotation in chunk_annotations:\n",
        "            for ann in chunk_annotation.annotations:\n",
        "                rows.append({\n",
        "                    'chunk_index': chunk_annotation.chunk_index,\n",
        "                    'annotation_text': ann.text,\n",
        "                    'start_position': ann.start,\n",
        "                    'end_position': ann.end,\n",
        "                    'type': ann.type,\n",
        "                    'subtype': ann.subtype,\n",
        "                    'text_length': len(ann.text),\n",
        "                    'chunk_length': chunk_annotation.chunk_size,\n",
        "                    'processing_time': chunk_annotation.processing_time,\n",
        "                    'confidence': ann.confidence,\n",
        "                    'source': source_info\n",
        "                })\n",
        "\n",
        "        return pd.DataFrame(rows) if rows else pd.DataFrame()\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_json_output(chunk_annotations: List[ChunkAnnotation],\n",
        "                           source_info: str = \"user_input\") -> Dict[str, Any]:\n",
        "        \"\"\"Generate JSON output for ML training.\"\"\"\n",
        "        output = {\n",
        "            \"metadata\": {\n",
        "                \"created\": time.strftime('%Y-%m-%d %H:%M:%S'),\n",
        "                \"total_chunks\": len(chunk_annotations),\n",
        "                \"source\": source_info,\n",
        "                \"taxonomy\": TAXONOMY\n",
        "            },\n",
        "            \"annotations\": []\n",
        "        }\n",
        "\n",
        "        total_annotations = 0\n",
        "\n",
        "        for chunk_annotation in chunk_annotations:\n",
        "            chunk_data = {\n",
        "                \"chunk_index\": chunk_annotation.chunk_index,\n",
        "                \"original_text\": chunk_annotation.original_text,\n",
        "                \"text_length\": chunk_annotation.chunk_size,\n",
        "                \"processing_time\": chunk_annotation.processing_time,\n",
        "                \"annotations\": chunk_annotation.to_ml_format()\n",
        "            }\n",
        "\n",
        "            output[\"annotations\"].append(chunk_data)\n",
        "            total_annotations += len(chunk_annotation.annotations)\n",
        "\n",
        "        # Add summary statistics\n",
        "        output[\"metadata\"][\"total_annotations\"] = total_annotations\n",
        "\n",
        "        # Calculate statistics\n",
        "        type_counts = Counter()\n",
        "        subtype_counts = Counter()\n",
        "\n",
        "        for chunk in chunk_annotations:\n",
        "            for ann in chunk.annotations:\n",
        "                type_counts[ann.type] += 1\n",
        "                subtype_counts[f\"{ann.type}:{ann.subtype}\"] += 1\n",
        "\n",
        "        output[\"metadata\"][\"statistics\"] = {\n",
        "            \"type_counts\": dict(type_counts),\n",
        "            \"subtype_counts\": dict(subtype_counts)\n",
        "        }\n",
        "\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# MAIN ANNOTATOR CLASS\n",
        "# =============================================================================\n",
        "\n",
        "class MedievalTextAnnotator:\n",
        "    \"\"\"\n",
        "    Main annotation class for Medieval Spanish/Catalan texts.\n",
        "\n",
        "    This class provides a simple interface for annotating texts with\n",
        "    medieval literary taxonomy, producing outputs in XML, CSV, and JSON formats.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, api_key: str, model_name: str = 'gemini-1.5-flash'):\n",
        "        \"\"\"\n",
        "        Initialize the Medieval Text Annotator.\n",
        "\n",
        "        Args:\n",
        "            api_key: Your Gemini API key\n",
        "            model_name: Gemini model to use (default: 'gemini-1.5-flash')\n",
        "        \"\"\"\n",
        "        self.api_key = api_key\n",
        "        self.model_name = model_name\n",
        "\n",
        "        # Initialize components\n",
        "        self.text_processor = TextProcessor()\n",
        "        self.llm_annotator = LLMAnnotator(api_key, model_name)\n",
        "        self.output_generator = OutputGenerator()\n",
        "\n",
        "        # Set up logging\n",
        "        logging.basicConfig(\n",
        "            level=logging.INFO,\n",
        "            format='%(asctime)s - %(levelname)s - %(message)s'\n",
        "        )\n",
        "\n",
        "        logging.info(\"Medieval Text Annotator initialized successfully\")\n",
        "\n",
        "    def annotate_text(self, text: str, max_chunk_size: int = 1500) -> AnnotationResult:\n",
        "        \"\"\"\n",
        "        Annotate Spanish/Catalan text with medieval literary taxonomy.\n",
        "\n",
        "        Args:\n",
        "            text: Raw text to annotate\n",
        "            max_chunk_size: Maximum characters per chunk for processing\n",
        "\n",
        "        Returns:\n",
        "            AnnotationResult containing all three output formats\n",
        "        \"\"\"\n",
        "        if not text or not text.strip():\n",
        "            return self._create_empty_result()\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        try:\n",
        "            # Step 1: Clean the input text\n",
        "            logging.info(\"Starting text annotation process...\")\n",
        "            cleaned_text = self.text_processor.clean_extracted_text(text)\n",
        "\n",
        "            if not cleaned_text:\n",
        "                logging.warning(\"Text cleaning resulted in empty text\")\n",
        "                return self._create_empty_result()\n",
        "\n",
        "            # Step 2: Chunk the text intelligently\n",
        "            chunks = self.text_processor.chunk_text_intelligently(cleaned_text, max_chunk_size)\n",
        "\n",
        "            if not chunks:\n",
        "                logging.warning(\"Text chunking resulted in no chunks\")\n",
        "                return self._create_empty_result()\n",
        "\n",
        "            # Step 3: Annotate each chunk\n",
        "            chunk_annotations = []\n",
        "\n",
        "            for i, chunk in enumerate(chunks):\n",
        "                logging.info(f\"Processing chunk {i+1}/{len(chunks)}...\")\n",
        "                chunk_annotation = self.llm_annotator.annotate_chunk(chunk, i)\n",
        "                chunk_annotations.append(chunk_annotation)\n",
        "\n",
        "                # Small delay to avoid rate limiting\n",
        "                if i < len(chunks) - 1:\n",
        "                    time.sleep(0.5)\n",
        "\n",
        "            # Step 4: Generate all output formats\n",
        "            total_processing_time = time.time() - start_time\n",
        "\n",
        "            xml_output = self.output_generator.generate_xml_output(chunk_annotations)\n",
        "            csv_output = self.output_generator.generate_csv_output(chunk_annotations)\n",
        "            json_output = self.output_generator.generate_json_output(chunk_annotations)\n",
        "\n",
        "            # Calculate statistics\n",
        "            total_annotations = sum(len(chunk.annotations) for chunk in chunk_annotations)\n",
        "            statistics = self._calculate_statistics(chunk_annotations)\n",
        "\n",
        "            logging.info(f\"Annotation complete: {total_annotations} annotations in {total_processing_time:.2f}s\")\n",
        "\n",
        "            return AnnotationResult(\n",
        "                xml_output=xml_output,\n",
        "                csv_output=csv_output,\n",
        "                json_output=json_output,\n",
        "                total_annotations=total_annotations,\n",
        "                processing_time=total_processing_time,\n",
        "                chunk_count=len(chunks),\n",
        "                statistics=statistics,\n",
        "                chunks=chunk_annotations\n",
        "            )\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error during annotation: {e}\")\n",
        "            logging.error(traceback.format_exc())\n",
        "            return self._create_error_result(str(e))\n",
        "\n",
        "    def annotate_batch(self, texts: List[str], max_chunk_size: int = 1500) -> List[AnnotationResult]:\n",
        "        \"\"\"\n",
        "        Annotate multiple texts in batch.\n",
        "\n",
        "        Args:\n",
        "            texts: List of texts to annotate\n",
        "            max_chunk_size: Maximum characters per chunk for processing\n",
        "\n",
        "        Returns:\n",
        "            List of AnnotationResult objects\n",
        "        \"\"\"\n",
        "        results = []\n",
        "\n",
        "        for i, text in enumerate(texts):\n",
        "            logging.info(f\"Processing text {i+1}/{len(texts)}\")\n",
        "            result = self.annotate_text(text, max_chunk_size)\n",
        "            results.append(result)\n",
        "\n",
        "            # Delay between texts to avoid rate limiting\n",
        "            if i < len(texts) - 1:\n",
        "                time.sleep(1.0)\n",
        "\n",
        "        return results\n",
        "\n",
        "    def get_taxonomy(self) -> Dict[str, List[str]]:\n",
        "        \"\"\"Get the current taxonomy structure.\"\"\"\n",
        "        return TAXONOMY.copy()\n",
        "\n",
        "    def validate_text(self, text: str) -> Tuple[bool, str]:\n",
        "        \"\"\"\n",
        "        Validate input text for annotation.\n",
        "\n",
        "        Args:\n",
        "            text: Text to validate\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (is_valid, error_message)\n",
        "        \"\"\"\n",
        "        if not text:\n",
        "            return False, \"Text is empty\"\n",
        "\n",
        "        if not isinstance(text, str):\n",
        "            return False, \"Text must be a string\"\n",
        "\n",
        "        if len(text.strip()) < 10:\n",
        "            return False, \"Text too short (minimum 10 characters)\"\n",
        "\n",
        "        if len(text) > 100000:\n",
        "            return False, \"Text too long (maximum 100,000 characters)\"\n",
        "\n",
        "        return True, \"Text is valid\"\n",
        "\n",
        "    def get_xml_output(self, result: AnnotationResult) -> str:\n",
        "        \"\"\"\n",
        "        Get XML output from annotation result.\n",
        "\n",
        "        Args:\n",
        "            result: AnnotationResult object\n",
        "\n",
        "        Returns:\n",
        "            XML string with embedded annotations\n",
        "        \"\"\"\n",
        "        return result.xml_output\n",
        "\n",
        "    def get_csv_output(self, result: AnnotationResult) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Get CSV output from annotation result.\n",
        "\n",
        "        Args:\n",
        "            result: AnnotationResult object\n",
        "\n",
        "        Returns:\n",
        "            pandas DataFrame with annotation data\n",
        "        \"\"\"\n",
        "        return result.csv_output\n",
        "\n",
        "    def get_json_output(self, result: AnnotationResult) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Get JSON output from annotation result.\n",
        "\n",
        "        Args:\n",
        "            result: AnnotationResult object\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with ML training format data\n",
        "        \"\"\"\n",
        "        return result.json_output\n",
        "\n",
        "    def save_results(self, result: AnnotationResult, output_dir: str,\n",
        "                    base_filename: str = \"annotations\") -> Dict[str, str]:\n",
        "        \"\"\"\n",
        "        Save annotation results to files.\n",
        "\n",
        "        Args:\n",
        "            result: AnnotationResult to save\n",
        "            output_dir: Directory to save files\n",
        "            base_filename: Base filename for outputs\n",
        "\n",
        "        Returns:\n",
        "            Dictionary mapping format to file path\n",
        "        \"\"\"\n",
        "        return result.save_outputs(output_dir, base_filename)\n",
        "\n",
        "    def get_statistics(self, result: AnnotationResult) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Get detailed statistics from annotation result.\n",
        "\n",
        "        Args:\n",
        "            result: AnnotationResult object\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with annotation statistics\n",
        "        \"\"\"\n",
        "        return result.statistics\n",
        "\n",
        "    def _create_empty_result(self) -> AnnotationResult:\n",
        "        \"\"\"Create an empty annotation result.\"\"\"\n",
        "        empty_df = pd.DataFrame(columns=[\n",
        "            'chunk_index', 'annotation_text', 'start_position', 'end_position',\n",
        "            'type', 'subtype', 'text_length', 'chunk_length', 'processing_time',\n",
        "            'confidence', 'source'\n",
        "        ])\n",
        "\n",
        "        return AnnotationResult(\n",
        "            xml_output=\"<annotated_text><metadata><summary total_annotations='0'/></metadata><body></body></annotated_text>\",\n",
        "            csv_output=empty_df,\n",
        "            json_output={\"metadata\": {\"total_annotations\": 0}, \"annotations\": []},\n",
        "            total_annotations=0,\n",
        "            processing_time=0.0,\n",
        "            chunk_count=0,\n",
        "            statistics={\"type_counts\": {}, \"subtype_counts\": {}},\n",
        "            chunks=[]\n",
        "        )\n",
        "\n",
        "    def _create_error_result(self, error_message: str) -> AnnotationResult:\n",
        "        \"\"\"Create an error annotation result.\"\"\"\n",
        "        empty_df = pd.DataFrame(columns=[\n",
        "            'chunk_index', 'annotation_text', 'start_position', 'end_position',\n",
        "            'type', 'subtype', 'text_length', 'chunk_length', 'processing_time',\n",
        "            'confidence', 'source'\n",
        "        ])\n",
        "\n",
        "        return AnnotationResult(\n",
        "            xml_output=f\"<annotated_text><error>{error_message}</error></annotated_text>\",\n",
        "            csv_output=empty_df,\n",
        "            json_output={\"error\": error_message, \"annotations\": []},\n",
        "            total_annotations=0,\n",
        "            processing_time=0.0,\n",
        "            chunk_count=0,\n",
        "            statistics={\"error\": error_message},\n",
        "            chunks=[]\n",
        "        )\n",
        "\n",
        "    def _calculate_statistics(self, chunk_annotations: List[ChunkAnnotation]) -> Dict[str, Any]:\n",
        "        \"\"\"Calculate detailed statistics for annotation results.\"\"\"\n",
        "        if not chunk_annotations:\n",
        "            return {\"type_counts\": {}, \"subtype_counts\": {}}\n",
        "\n",
        "        type_counts = Counter()\n",
        "        subtype_counts = Counter()\n",
        "        text_lengths = []\n",
        "        processing_times = []\n",
        "\n",
        "        for chunk in chunk_annotations:\n",
        "            processing_times.append(chunk.processing_time)\n",
        "\n",
        "            for ann in chunk.annotations:\n",
        "                type_counts[ann.type] += 1\n",
        "                subtype_counts[f\"{ann.type}:{ann.subtype}\"] += 1\n",
        "                text_lengths.append(len(ann.text))\n",
        "\n",
        "        statistics = {\n",
        "            \"type_counts\": dict(type_counts),\n",
        "            \"subtype_counts\": dict(subtype_counts),\n",
        "            \"avg_processing_time\": sum(processing_times) / len(processing_times) if processing_times else 0,\n",
        "            \"total_processing_time\": sum(processing_times),\n",
        "            \"avg_annotation_length\": sum(text_lengths) / len(text_lengths) if text_lengths else 0,\n",
        "            \"annotation_density\": len(text_lengths) / sum(chunk.chunk_size for chunk in chunk_annotations) if chunk_annotations else 0\n",
        "        }\n",
        "\n",
        "        return statistics"
      ],
      "metadata": {
        "id": "QYSah2KtuW1V"
      },
      "execution_count": 3,
      "outputs": []
    }
  ]
}